1 3D视觉技术在机器人抓取作业中的应用_李刚
提取信息：
（1）3D表面成像技术：
双目立体视觉（binocular stereo vision）
多目立体视觉（multi-view stereo vision）
线结构光三角测量（laser triangulation with sheet of ligt）
编码结构光三角测量（encoded structured light）
飞行时间深度测量（time of flight）
聚焦深度测量（depthfrom focus）
光度立体视觉（photometric stereo vision）
（2）3D视觉处理算法
1　点云滤波
功能：可实现去噪、平滑、采样、特征提取等功能
算法：双边滤波、高斯滤波、条件滤波、随机采样一致性滤波等
2　点云特征估计
    2.1 点云局部特征估计：特征包括法向量、曲率、边界、点特征直方图（PFH）、快速点特征直方图（FPFH）、视角特征
直方图（VFH）、NARF描述子、旋转投影统计特征（Rotational Projection Statistics）
    2.2 点云整体特征估计：点云的表面积、最小外接盒、最大直径、截面曲线
3　点云关键点提取
算法：Harris3D、ISS3D、NARF、SIFT、SUSAN、Trajkovic3D。
4　点云配准
由于遮挡等原因，为了获得完整的目标表面3D点云，常常需要从不同的视角对同一目标物体进行扫描。
点云配准（registration）技术是将这些点云数据两两进行匹配
5　点云分割
如平面分割、柱面分割、欧几里得聚类提取、超体聚类分割、区域生长分割、基于最小割的点云分割、基于法
向量差的点云分割等。除了上述的3D点云分割方法，点云的分割也可结合2D图像进行。先在2D图像上应用边缘提取、深度学习等算法，然后再对点云进行分割
6　三维匹配
功能是在搜索数据中找到目标物体并确定它的3D位姿
7　点云拟合
某个点云子集为已知的几何形状，如平面、柱面、球面，可利用点云拟合算法进行拟合求出相应的位姿和几何参数信息
总结：前四个算法步骤还是分割的前提，然后再近些6或者7估算出目标物体的位姿
---------------------------------------------------------------------------------------------------------------------------------------------
2 
名字：基于２Ｄ－３Ｄ语义传递的室内三维点云模型语义分割
出版类型：EI
出版名字：武汉大学报（信息科学版）
发表时间：2018_12_05
贡献：本文提出了一种基于 图 模 型的二维图像语义到三维点云语义的传递算法，通过将实景图像作为语义分类的信息源，然后基于
ＦＣＮ算 法 对 室 内 图像对象语义分类和空间布局提取，探索融合图像间一致性和图像内一致性的图模型，以此实现从２Ｄ图像到３Ｄ 点 云 的 语 义 传 递 和 分 割。
困难：现有三维点云模型重建对象化和结构化信息缺失的问题
结果：本文方法能得到精度较高的室内三维点云的精细结构化语义分割模型，并且能够有效地规避缺乏３Ｄ特征描述算子和训练数据集的问题。
得到精度较高的室内三维点云语义分类结果，点云分类的精度可达到73.8752％，且分类效果较好

研究背景：
对象化和结构化的信息损失，室内空间的封闭性和复杂性，且3D特征描述算子困难，所以室内3维点云模型的语义提取和对象分类非常苦难
室内模型不仅需要表达对象信息，还需要表达结构信息
以前方法：
直接借鉴二维的研究思路，基于3D几何特征逐进行分类器训练，并通过空间上下文约束进行优化，得到语义分类结果
现在方法：
3D shapenet 构建3D卷积网络，从体素学习特诊描述算子，但缺点是很难构造有效的3D特征
Ｋｏｐｐｕｌａ等［７］提出 利 用 多 维 特 征 和 上下文关系构建图模型进行语义分类的方法，结合图像局部纹理特征、形状先验特征、对象关系特征提高３Ｄ特征算子的鲁棒性
袁 理 等［１６］提出 了 一种针对待建图像动态选择２Ｄ－３Ｄ特征变换子空间的策略，能显著提高重建精度
Ｂｏｕｌｃｈ等［１４］利用卷积神经网络图像分类方法对三维点云模型实现逐点云的语义类别标注［１４］。相比于直接对３Ｄ点云数据进行分割和
语义标注，该方法避免了构建３Ｄ特征算子和训练数据集，实现了三维点云的语义对象获取。然而，该方法没有考虑图像之间的空间上下文一致性
本文见上
---------------------------------------------------------------------------------------------------------------------------------------------
3
名字：三维点云数据分割研究现状
出版类型：
出版名字：宜宾学院学报
发表时间：2016_11_10
贡献:介绍三维点云数据分割的基本原理和特征，以及经典的点云数据集和测试平台，总结、对比现阶段各类点云分割算法的基本原理、特点和适用场景
困难：现有算法的自适应能力差，大部分算法对异常点和噪声敏感，且效率也有待提升
结果：未来研究需充分利用点云数据的语境信息，进一步结合深度学习理论，从而提升点云分割效果


研究背景：点云数据通常是无序，稀疏的，且有大量的噪声点和异常点，扫描仪的局限性
点云数据采集密度也是不均匀的，点云数据的分割难度很大

点云分割算法分类：
1 基于边缘的分割方法
2 基于区域增长的分割算法
3 基于属性的分割算法
4 基于模型的分割算法
5 基于图的分割算法
6 混合的分割算法
现在方法：结合深度学习
---------------------------------------------------------------------------------------------------------------------------------------------
4
名字：三维点云场景数据获取及其场景理解关键技术综述
出版类型：北大中文核心
出版名字：激光与光电子学进展
发表时间：2018_09_14
贡献:
总结了不同方式的点云获取方法，对不同的点云数据及相关数据库进行了对比分析
点云语义分割技术进行了对比分析与总结
困难：
三维场景理解关键技术存在的问题，尤其是针对具有颜色信息的激光点云的场景理解
结果：

研究背景：二维图像的场景可能会存在光照不均匀，目标遮挡等现象，且不包含深度信息
因此，基于二维图像数据的场景理解鲁棒性差，且难以精确地提取目标轮廓，空间位置等关键信息


深度学习方法：
真毒点云的深度学习网络主要分为三大类
（1）基于2D投影的深度学习网络
MVCNN[40],Snapnet[42],DeePr3SS[43]等方法采用多视角投影的方法进行点云的分类。目前，Snapnet 和 DeePr3SS 的分类效果在 Semantic 3D 数据集的 reduced-8 上的 Benchmark 排名分别为第 7 和第 9
[44].由此，可知，这类方法还存在很多改进的空间。此外，这类方法会容易造成三维结构信息的丢失，而且投影角度的选取，同一角度的投影对物体的表征能力也不同，对网络的泛化能力有一定的影响
（2）基于3D体素化的卷积神经网络
Daniel 等[45]基于监督三维卷积神经网络和点云体素化提出了 VoxNet 网络模型；Gernot 团队[46]提出 OctNet 网络模型
为了提高体素的表征能力，相继的提出了多种多尺度体素的卷积神经网络方法，如 Semantic 3D Net[8]，MS3_DVS[48]，MVSNet
（3）基于点云中单个点的网络模型
斯坦福大学 Charles 团队[51]针对室内的点云场景提出了 PointNet，对室内点云数据进行了分类、部分分割、语义分割三部分工作，而后，针对 PointNet 中局部特征信息进行了改进，
推向多尺度，综合局部特征，提出了 PointNet++网络模型[52]；Yangyan
Li[53]等人在 PointNet 基础上进行改进，提出 PointCNN，该方法通过对点云特性的分析，提出了一种基于点云中点学习到的 X 变换方法，然后将其用于同时加权与点关联的输入特征和将它们重新排列成潜在隐含的规范顺序，
之后再在元素上应用求积和求和运算。虽然所提算法能够对点云卷积处理的性能有所提高，但 X-transformations 还有较大的改进空间，尤其是在排序方面
最新的 SO-net[54]的提出以及对 pointnet 改进提出的 PointFlowNet[55]等网络模型均取得了较好的效果，但是对于大规模点云还具有一定的局限性

---------------------------------------------------------------------------------------------------------------------------------------------
5 
名字：Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs
出版类型：IEEE
出版名字：CVPR 2018
发表时间：2017_11_27
贡献：提出了一个深度学习框架来解决大规模点云的语义分割任务：SPGraph
目前在Semantic3D数据集的Benchmark中排名第一
介绍了超点图，
困难：数据的规模and缺乏类似于图像中的规则网格排列的清晰结构
结果：在Semantic3D数据集中，mIOU为0.762 ，OA为0.929


---------------------------------------------------------------------------------------------------------------------------------------------
6 
名字：Multi-view Convolutional Neural Networks for 3D Shape Recognition
出版类型：IEEE
出版名字：ICCV2015
发表时间：2015
贡献：将3D点云投影到2D图像后作为卷积神经网络输入，创造了MVCNN（同类型snapnet）
困难：这类方法会容易造成三维结构信息的丢失，而且投影角度的选取，同一角度的投影
对物体的表征能力也不同，对网络的泛化能力有一定的影响
结果： 在Princeton ModelNet dataset 取得89.9% classification accuracy, and 70.1% mAP on retrieval


---------------------------------------------------------------------------------------------------------------------------------------------
7 
名字：Deep Projective 3D Semantic Segmentation
出版类型：
出版名字：CAIP2017
发表时间：2017_8_22
贡献：将点云组合到2D图像上，然后将这些图像用作到2D-CNN，提出DeePr3SS
调查了不同输入模态的影响，例如颜色，深度和表面法线
困难：这类方法会容易造成三维结构信息的丢失，而且投影角度的选取，同一角度的投影
对物体的表征能力也不同，对网络的泛化能力有一定的影响
结果：在Semantic3D数据集中，mIOU为0.585，OA为0.889


---------------------------------------------------------------------------------------------------------------------------------------------
8
名字：VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition
出版类型：IEEE
出版名字：IROS 2015
发表时间：2015
贡献：在2D CNN的基础上，提出了VoxNet,一个监督形的3D卷积神经网络
通过网络化提供了点云结构，网格的转换解决了排列问题
困难：卷积计算量非常大，网络中仅利用了点云的结构信息，没有考虑到点云的颜色
，强度等信息
结果：


---------------------------------------------------------------------------------------------------------------------------------------------
9
名字：PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation
出版类型：IEEE
出版名字：CVPR 2017
发表时间：2017_07
贡献：提出了PointNet框架
困难：对大规模点云还具有一定的局限性,不会捕获度量空间点引起的局部结构，限制了它识别细粒度模式的能力
无法处理局部特征
结果：在stanford 3D semantic parsing dataset上 mIoU为0.4771，OA为0.7862


---------------------------------------------------------------------------------------------------------------------------------------------
10 
名字：PointNet++: Deep Hierarchical Feature Learning onPoint Sets in a Metric Space
出版类型：
出版名字：AIPS 2017
发表时间：2017
贡献：针对PointNet局部特征信息进行了改进，推向多尺度，综合局部特征
提出了PointNet++
实现了鲁棒性和细节捕捉
困难：如何生成点集的分区，以及如何通过本地特征学习器抽象点集或局部特征
点采样和分组策略没有揭示出入点云的空间分布
结果：Scannet labeling accuracy 是0.833

---------------------------------------------------------------------------------------------------------------------------------------------
11 
名字：PointCNN: Convolution On X -Transformed Points
出版类型：
出版名字：AIPS 2018
发表时间：2018
贡献：提出了PointCNN
通过对点云特性的分析，提出了一种基于点云中点学习到的X变化方法，对点云卷积处理
的性能有所提高
困难：X-transformations还有较大的改进空间，尤其是在排序方面
结果：在ShapeNet Parts数据集上，pIoU为0.8614，mpIoU为0.846
在S3DIS数据集上mIoU数据集为0.6539
在ScanNet数据集上的OA为0.851

---------------------------------------------------------------------------------------------------------------------------------------------
12 
名字：SO-Net: Self-Organizing Network for Point Cloud Analysis
出版类型: IEEE
出版名字：CVPR 2018
发表时间：2018_03_12
贡献：
提出了SO-net
提出了点云自编码器作为预训练在各种任务中提高网络性能
低计算成本
困难：网络可能无法正确注释细粒度的细节
结果：在ShapeNetPart dataset数据集中，IoU为0.846,预训练IoU为0.849

---------------------------------------------------------------------------------------------------------------------------------------------
13 
名字：SEGCloud: Semantic Segmentation of 3D Point Clouds
出版类型:   arxiv
出版名字：Proceedings of the International Conference on 3D Vision
发表时间：2017_10_20 
贡献：提出了SegCloud,获得3D点级的端到端框架
困难：
结果：在Semantic3D数据集上的mIOU为0.6310，mAcc为0.7308


